# Email AI Classifier

Este projeto √© uma solu√ß√£o completa de engenharia de software para o desafio de triagem e resposta automatizada de e-mails corporativos. O sistema utiliza Intelig√™ncia Artificial Generativa (Google Gemini via Vertex AI) para classificar mensagens recebidas entre "Produtivas" e "Improdutivas" e sugerir respostas contextualizadas, reduzindo o tempo gasto em tarefas operacionais manuais.

## Tecnologias Utilizadas

A arquitetura foi desenhada priorizando performance, manutenibilidade e escalabilidade serverless.

*   **FastAPI**: Framework web moderno e de alta performance. Escolhido por seu suporte nativo a programa√ß√£o ass√≠ncrona, valida√ß√£o de dados via Pydantic e facilidade de cria√ß√£o de APIs RESTful.
*   **Google Vertex AI (Gemini 2.5-pro)**: Motor de IA Generativa. Utilizado pela sua janela de contexto, capacidade de racioc√≠nio l√≥gico e integra√ß√£o segura via IAM (sem chaves de API expostas no c√≥digo).
*   **HTMX & Jinja2**: Abordagem *Hypermedia-Driven*. Permite interatividade din√¢mica no frontend (SPA-feel) sem a complexidade de build steps de frameworks como React/Vue, mantendo a renderiza√ß√£o no servidor (SSR) e simplificando a stack.
*   **uv**: Gerenciador de pacotes e projetos Python ultra-r√°pido (substituto moderno ao pip/poetry), garantindo builds determin√≠sticos e tempos de instala√ß√£o reduzidos no CI/CD.
*   **Docker & Cloud Run**: O projeto foi containerizado para ser agn√≥stico de infraestrutura, pronto para deploy escal√°vel e *stateless* no Google Cloud Run.
*   **pdfminer.six**: Biblioteca robusta para extra√ß√£o de texto de PDFs, permitindo que o sistema processe anexos al√©m de texto puro.
*   **Tailwind CSS**: Framework *utility-first* para estiliza√ß√£o r√°pida e responsiva, mantendo um design system consistente.

## Como Rodar o Projeto Localmente

### Pr√©-requisitos
*   Python 3.10+
*   [uv](https://github.com/astral-sh/uv) instalado
*   Acesso a um projeto Google Cloud com a API Vertex AI habilitada
*   **Configura√ß√£o de Autentica√ß√£o GCP** (Veja instru√ß√µes detalhadas abaixo)

### 1. Instala√ß√£o e Configura√ß√£o

Clone o reposit√≥rio e instale as depend√™ncias:

```bash
git clone https://github.com/seu-usuario/email-ai-classifier.git
cd email-ai-classifier
uv sync
```

**Configura√ß√£o do Ambiente e GCP:**

Para configurar corretamente o projeto no Google Cloud (criar Service Account, baixar chaves JSON) e conectar sua aplica√ß√£o local, siga o guia dedicado:

üëâ **[Guia Passo-a-Passo: Configura√ß√£o GCP e Vari√°veis de Ambiente](GCP_SETUP.md)** üëà

Ap√≥s seguir o guia acima, seu arquivo `.env` estar√° pronto.

### 2. Executando a Aplica√ß√£o

Inicie o servidor de desenvolvimento:

```bash
uv run uvicorn app.main:app --reload --port 8080
```

Acesse a interface em: `http://localhost:8080`

### 3. Via Docker (Alternativa)

```bash
docker build -t email-classifier .
docker run -p 8080:8080 --env-file .env -v ~/.config/gcloud:/root/.config/gcloud email-classifier
```
*Nota: A montagem de volume do gcloud √© necess√°ria para autentica√ß√£o local dentro do container, a menos que esteja usando Service Account keys.*

## Como Funciona a IA

A intelig√™ncia do sistema reside na orquestra√ß√£o de prompts e chamadas √† API Vertex AI.

### Classifica√ß√£o (Produtivo vs Improdutivo)
O core da classifica√ß√£o utiliza o modelo **Gemini 2.5-pro** com temperatura `0.0` para maximizar o determinismo.
1.  **Extra√ß√£o**: O texto √© extra√≠do de inputs diretos ou arquivos PDF, passando por limpeza de HTML e *stopwords*.
2.  **Prompt Engineering**: Um prompt estruturado (`app/prompts/email_classifier.prompt`) define regras r√≠gidas de neg√≥cio. Ele instrui o modelo a analisar a *intencionalidade* do e-mail (ex: solicita√ß√£o de a√ß√£o vs. notifica√ß√£o autom√°tica) e n√£o apenas palavras-chave.
3.  **Output Estruturado**: O modelo √© for√ßado a retornar um JSON estrito contendo `category`, `confidence` (0.0 a 1.0) e `reason`. Isso garante que a aplica√ß√£o possa tratar a resposta programaticamente sem falhas de *parsing*.

### Gera√ß√£o de Resposta
Caso o e-mail seja classificado, o sistema aciona um segundo fluxo (pipeline) que gera uma sugest√£o de resposta baseada na categoria e no conte√∫do original, mantendo tom profissional e objetivo.

## Decis√µes T√©cnicas

*   **Renderiza√ß√£o Server-Side com HTMX**: Optei por n√£o separar o frontend em um reposit√≥rio/build isolado (ex: Next.js) para reduzir a complexidade operacional. O HTMX permite atualiza√ß√µes parciais da DOM (via AJAX) retornando HTML do backend, o que √© ideal para ferramentas internas e dashboards administrativos onde o SEO n√£o √© prioridade, mas a velocidade de desenvolvimento √©.
*   **Seguran√ßa via IAM**: N√£o h√° chaves de API "hardcoded". O uso de `vertexai.init()` aproveita o *Application Default Credentials* (ADC) do Google. Isso significa que a seguran√ßa √© gerenciada por roles do IAM (Identity and Access Management), pr√°tica recomendada para ambientes corporativos.
*   **Valida√ß√£o Defensiva**: O c√≥digo implementa tratativas espec√≠ficas para alucina√ß√µes de formato do LLM (ex: `InvalidResponseJsonError`). Mesmo com instru√ß√µes claras, LLMs podem falhar; o sistema est√° preparado para capturar esses erros e informar o usu√°rio elegantemente.
*   **Arquitetura em Camadas**:
    *   `app/api`: Apenas defini√ß√£o de rotas e inje√ß√£o de depend√™ncias.
    *   `app/services`: L√≥gica de neg√≥cio e integra√ß√£o com Vertex AI.
    *   `app/prompts`: Prompts externalizados em arquivos `.prompt` para facilitar ajustes sem necessidade de *redeploy* de c√≥digo.

## Limita√ß√µes e Melhorias Futuras

Embora funcional, esta vers√£o representa um MVP (Minimum Viable Product). Em um cen√°rio de produ√ß√£o em larga escala, as seguintes evolu√ß√µes seriam priorit√°rias:

### Limita√ß√µes Atuais
*   **Chamadas S√≠ncronas**: Atualmente, a chamada ao Vertex AI bloqueia a thread de execu√ß√£o. Embora o FastAPI gerencie isso com threadpools, sob alta carga, isso pode se tornar um gargalo.
*   **Contexto √önico**: O sistema analisa cada e-mail isoladamente, sem conhecimento de threads anteriores ou hist√≥rico do cliente.

### Roadmap de Melhorias
1.  **Assincronismo Real**: Migrar para a vers√£o `AsyncGenerativeModel` do SDK da Vertex AI para liberar o *Event Loop* durante a infer√™ncia, aumentando drasticamente o throughput.
2.  **Fila de Processamento (Celery/Arq)**: Para volumes massivos, mover o processamento de IA para background jobs, retornando um ID de tarefa para o frontend (polling ou WebSocket).
3.  **Feedback Loop (RLHF)**: Implementar bot√µes de "Joinha/Joinha invertido" na interface para coletar feedback humano sobre a classifica√ß√£o e refinar o modelo via *Fine-tuning* ou *Few-shot prompting* din√¢mico.
4.  **Cache Sem√¢ntico**: Utilizar Redis para armazenar hash de e-mails repetidos (comuns em spam/notifica√ß√µes), economizando custos de API.
5.  **Observabilidade**: Implementar OpenTelemetry para rastrear lat√™ncia das chamadas ao Gemini e custos por token.
